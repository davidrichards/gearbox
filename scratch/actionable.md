I just [watched a video](http://t.co/Z7IutlEY) by Jeremy Howard: From Predictive Modeling to Optimization, the Next Frontier.  It was a good presentation.  From it, we get a simple framework:

1) Identify the objective. (find the web page you want to read)
2) What levers do you have to pull?  (ordering sites)
3) What data do we have, or can we collect to hook the levers to the objective? (Those that like X might also like Y)
4) Hook together the levers to the objective using the data (invent a data mining algorithm, PageRank)

The examples in parenthesis are for the search engine industry.  

The fourth part, hooking it all together, can be three steps.  You need to build:

1) Modeller
2) Simulator
3) Optimizer

This can be demonstrated with the insurance agency.  They model the predictive analytics.  They built a simulator to simulate/gather causal data.  They build an optimizer to find the best solution.  

This is decision support, in a nutshell.

Using Gearbox for this is the goal of openmobi.us, and my work in general.

The implementation of this might be something like:

1) Build a knowledge base with a purpose.
2) Outline levers that could be used in decision making.
3) Build the knowledge base the way that knowledge bases are built.
4) Build some tools in Fathom to model, simulate, and optimize.  Also, build a dashboard, some visualizations, and a platform for accessing these services. 

Now we have a data product designed to help human beings with living better lives.  This could be applied in any area that I am willing to research deeply.  This seems to be the anxiety that I have anyway: to use Gearbox to research deeply and not lose the thread.





